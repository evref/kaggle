{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from files\n",
    "test_X = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Split data into X:parameters and y:output\n",
    "train_y = train[\"Survived\"]\n",
    "train_X = train.drop(columns=\"Survived\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning data\n",
    "\n",
    "def clean_data(data: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    to_drop = [\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]\n",
    "    data.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    # Rephrase male and female into discrete values between 0 and 1\n",
    "    data = data.replace(\"male\", 0)\n",
    "    data = data.replace(\"female\", 1)\n",
    "\n",
    "    # Calculate avg age to replace null values with\n",
    "    avg_age = round(sum(data[\"Age\"].dropna()) / len(data[\"Age\"].dropna()))\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(avg_age)\n",
    "\n",
    "    # Calculate max values for normalization of columns\n",
    "    max_age = max(data[\"Age\"])\n",
    "    max_pclass = max(data[\"Pclass\"])\n",
    "\n",
    "    # Normalize values\n",
    "    data[\"Pclass\"] /= max_pclass\n",
    "    data[\"Age\"] /= max_age\n",
    "\n",
    "    return data\n",
    "\n",
    "# Clean both train and test data\n",
    "ctrain = clean_data(train_X)\n",
    "ctest = clean_data(test_X)\n",
    "\n",
    "# Get labels\n",
    "train_labels = ctrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set seed for torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Put data onto tensors\n",
    "train_X_tensor = torch.tensor(ctrain.to_numpy())\n",
    "train_y_tensor = torch.tensor(train_y.to_numpy())\n",
    "test_X_tensor = torch.tensor(ctest.to_numpy())\n",
    "\n",
    "# Split data into training- and validation sets\n",
    "train_split = int(0.8 * len(train_X_tensor))\n",
    "X_train, y_train = train_X_tensor[:train_split], train_y_tensor[:train_split]\n",
    "X_valid, y_valid = train_X_tensor[train_split:], train_y_tensor[train_split:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer_1): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (layer_3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load neural network\n",
    "from torch import nn\n",
    "\n",
    "# Select device (aka cpu/gpu)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(f\"Using {device} device\")\n",
    "\n",
    "# Defining the neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=3, out_features=32)\n",
    "        self.layer_2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.layer_3 = nn.Linear(in_features=32, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        layer1 = self.layer_1(x)\n",
    "        layer2 = self.layer_2(layer1)\n",
    "        layer3 = self.layer_3(layer2)\n",
    "        return layer3\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.7491713762283325, Accuracy: 39.04494382022472\n",
      "Epoch 10: Loss: 0.5588670372962952, Accuracy: 75.84269662921348\n",
      "Epoch 20: Loss: 0.47447526454925537, Accuracy: 78.37078651685393\n",
      "Epoch 30: Loss: 0.4704074263572693, Accuracy: 78.37078651685393\n",
      "Epoch 40: Loss: 0.4677979052066803, Accuracy: 78.37078651685393\n",
      "Epoch 50: Loss: 0.46601659059524536, Accuracy: 78.37078651685393\n",
      "Epoch 60: Loss: 0.4648061990737915, Accuracy: 78.51123595505618\n",
      "Epoch 70: Loss: 0.46401742100715637, Accuracy: 78.51123595505618\n",
      "Epoch 80: Loss: 0.46357131004333496, Accuracy: 78.37078651685393\n",
      "Epoch 90: Loss: 0.5146408677101135, Accuracy: 77.24719101123596\n"
     ]
    }
   ],
   "source": [
    "# Set loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optim = torch.optim.SGD(params=model.parameters(), lr=1)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_true)) * 100\n",
    "    return acc\n",
    "\n",
    "# Amount of training epochs to run\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train.float()).flatten()\n",
    "    loss = loss_fn(y_pred, y_train.float())\n",
    "\n",
    "    # Backward pass\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "    acc = accuracy_fn(y_train, y_pred)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training: Loss: 0.46467265486717224, Accuracy: 78.51123595505618\n",
      "Validation: Loss: 0.42052748799324036, Accuracy: 80.44692737430168\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_valid_pred = model(X_valid.float()).flatten()\n",
    "\n",
    "print(f\"Final training: Loss: {loss.item()}, Accuracy: {acc}\")\n",
    "\n",
    "\n",
    "loss = loss_fn(y_valid_pred, y_valid.float())\n",
    "y_valid_pred = torch.round(torch.sigmoid(y_valid_pred))\n",
    "acc = accuracy_fn(y_valid, y_valid_pred)\n",
    "print(f\"Validation: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred_test = model(test_X_tensor.float()).flatten()\n",
    "\n",
    "y_pred_test = torch.round(torch.sigmoid(y_pred_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PassengerId': [892,\n",
       "  893,\n",
       "  894,\n",
       "  895,\n",
       "  896,\n",
       "  897,\n",
       "  898,\n",
       "  899,\n",
       "  900,\n",
       "  901,\n",
       "  902,\n",
       "  903,\n",
       "  904,\n",
       "  905,\n",
       "  906,\n",
       "  907,\n",
       "  908,\n",
       "  909,\n",
       "  910,\n",
       "  911,\n",
       "  912,\n",
       "  913,\n",
       "  914,\n",
       "  915,\n",
       "  916,\n",
       "  917,\n",
       "  918,\n",
       "  919,\n",
       "  920,\n",
       "  921,\n",
       "  922,\n",
       "  923,\n",
       "  924,\n",
       "  925,\n",
       "  926,\n",
       "  927,\n",
       "  928,\n",
       "  929,\n",
       "  930,\n",
       "  931,\n",
       "  932,\n",
       "  933,\n",
       "  934,\n",
       "  935,\n",
       "  936,\n",
       "  937,\n",
       "  938,\n",
       "  939,\n",
       "  940,\n",
       "  941,\n",
       "  942,\n",
       "  943,\n",
       "  944,\n",
       "  945,\n",
       "  946,\n",
       "  947,\n",
       "  948,\n",
       "  949,\n",
       "  950,\n",
       "  951,\n",
       "  952,\n",
       "  953,\n",
       "  954,\n",
       "  955,\n",
       "  956,\n",
       "  957,\n",
       "  958,\n",
       "  959,\n",
       "  960,\n",
       "  961,\n",
       "  962,\n",
       "  963,\n",
       "  964,\n",
       "  965,\n",
       "  966,\n",
       "  967,\n",
       "  968,\n",
       "  969,\n",
       "  970,\n",
       "  971,\n",
       "  972,\n",
       "  973,\n",
       "  974,\n",
       "  975,\n",
       "  976,\n",
       "  977,\n",
       "  978,\n",
       "  979,\n",
       "  980,\n",
       "  981,\n",
       "  982,\n",
       "  983,\n",
       "  984,\n",
       "  985,\n",
       "  986,\n",
       "  987,\n",
       "  988,\n",
       "  989,\n",
       "  990,\n",
       "  991,\n",
       "  992,\n",
       "  993,\n",
       "  994,\n",
       "  995,\n",
       "  996,\n",
       "  997,\n",
       "  998,\n",
       "  999,\n",
       "  1000,\n",
       "  1001,\n",
       "  1002,\n",
       "  1003,\n",
       "  1004,\n",
       "  1005,\n",
       "  1006,\n",
       "  1007,\n",
       "  1008,\n",
       "  1009,\n",
       "  1010,\n",
       "  1011,\n",
       "  1012,\n",
       "  1013,\n",
       "  1014,\n",
       "  1015,\n",
       "  1016,\n",
       "  1017,\n",
       "  1018,\n",
       "  1019,\n",
       "  1020,\n",
       "  1021,\n",
       "  1022,\n",
       "  1023,\n",
       "  1024,\n",
       "  1025,\n",
       "  1026,\n",
       "  1027,\n",
       "  1028,\n",
       "  1029,\n",
       "  1030,\n",
       "  1031,\n",
       "  1032,\n",
       "  1033,\n",
       "  1034,\n",
       "  1035,\n",
       "  1036,\n",
       "  1037,\n",
       "  1038,\n",
       "  1039,\n",
       "  1040,\n",
       "  1041,\n",
       "  1042,\n",
       "  1043,\n",
       "  1044,\n",
       "  1045,\n",
       "  1046,\n",
       "  1047,\n",
       "  1048,\n",
       "  1049,\n",
       "  1050,\n",
       "  1051,\n",
       "  1052,\n",
       "  1053,\n",
       "  1054,\n",
       "  1055,\n",
       "  1056,\n",
       "  1057,\n",
       "  1058,\n",
       "  1059,\n",
       "  1060,\n",
       "  1061,\n",
       "  1062,\n",
       "  1063,\n",
       "  1064,\n",
       "  1065,\n",
       "  1066,\n",
       "  1067,\n",
       "  1068,\n",
       "  1069,\n",
       "  1070,\n",
       "  1071,\n",
       "  1072,\n",
       "  1073,\n",
       "  1074,\n",
       "  1075,\n",
       "  1076,\n",
       "  1077,\n",
       "  1078,\n",
       "  1079,\n",
       "  1080,\n",
       "  1081,\n",
       "  1082,\n",
       "  1083,\n",
       "  1084,\n",
       "  1085,\n",
       "  1086,\n",
       "  1087,\n",
       "  1088,\n",
       "  1089,\n",
       "  1090,\n",
       "  1091,\n",
       "  1092,\n",
       "  1093,\n",
       "  1094,\n",
       "  1095,\n",
       "  1096,\n",
       "  1097,\n",
       "  1098,\n",
       "  1099,\n",
       "  1100,\n",
       "  1101,\n",
       "  1102,\n",
       "  1103,\n",
       "  1104,\n",
       "  1105,\n",
       "  1106,\n",
       "  1107,\n",
       "  1108,\n",
       "  1109,\n",
       "  1110,\n",
       "  1111,\n",
       "  1112,\n",
       "  1113,\n",
       "  1114,\n",
       "  1115,\n",
       "  1116,\n",
       "  1117,\n",
       "  1118,\n",
       "  1119,\n",
       "  1120,\n",
       "  1121,\n",
       "  1122,\n",
       "  1123,\n",
       "  1124,\n",
       "  1125,\n",
       "  1126,\n",
       "  1127,\n",
       "  1128,\n",
       "  1129,\n",
       "  1130,\n",
       "  1131,\n",
       "  1132,\n",
       "  1133,\n",
       "  1134,\n",
       "  1135,\n",
       "  1136,\n",
       "  1137,\n",
       "  1138,\n",
       "  1139,\n",
       "  1140,\n",
       "  1141,\n",
       "  1142,\n",
       "  1143,\n",
       "  1144,\n",
       "  1145,\n",
       "  1146,\n",
       "  1147,\n",
       "  1148,\n",
       "  1149,\n",
       "  1150,\n",
       "  1151,\n",
       "  1152,\n",
       "  1153,\n",
       "  1154,\n",
       "  1155,\n",
       "  1156,\n",
       "  1157,\n",
       "  1158,\n",
       "  1159,\n",
       "  1160,\n",
       "  1161,\n",
       "  1162,\n",
       "  1163,\n",
       "  1164,\n",
       "  1165,\n",
       "  1166,\n",
       "  1167,\n",
       "  1168,\n",
       "  1169,\n",
       "  1170,\n",
       "  1171,\n",
       "  1172,\n",
       "  1173,\n",
       "  1174,\n",
       "  1175,\n",
       "  1176,\n",
       "  1177,\n",
       "  1178,\n",
       "  1179,\n",
       "  1180,\n",
       "  1181,\n",
       "  1182,\n",
       "  1183,\n",
       "  1184,\n",
       "  1185,\n",
       "  1186,\n",
       "  1187,\n",
       "  1188,\n",
       "  1189,\n",
       "  1190,\n",
       "  1191,\n",
       "  1192,\n",
       "  1193,\n",
       "  1194,\n",
       "  1195,\n",
       "  1196,\n",
       "  1197,\n",
       "  1198,\n",
       "  1199,\n",
       "  1200,\n",
       "  1201,\n",
       "  1202,\n",
       "  1203,\n",
       "  1204,\n",
       "  1205,\n",
       "  1206,\n",
       "  1207,\n",
       "  1208,\n",
       "  1209,\n",
       "  1210,\n",
       "  1211,\n",
       "  1212,\n",
       "  1213,\n",
       "  1214,\n",
       "  1215,\n",
       "  1216,\n",
       "  1217,\n",
       "  1218,\n",
       "  1219,\n",
       "  1220,\n",
       "  1221,\n",
       "  1222,\n",
       "  1223,\n",
       "  1224,\n",
       "  1225,\n",
       "  1226,\n",
       "  1227,\n",
       "  1228,\n",
       "  1229,\n",
       "  1230,\n",
       "  1231,\n",
       "  1232,\n",
       "  1233,\n",
       "  1234,\n",
       "  1235,\n",
       "  1236,\n",
       "  1237,\n",
       "  1238,\n",
       "  1239,\n",
       "  1240,\n",
       "  1241,\n",
       "  1242,\n",
       "  1243,\n",
       "  1244,\n",
       "  1245,\n",
       "  1246,\n",
       "  1247,\n",
       "  1248,\n",
       "  1249,\n",
       "  1250,\n",
       "  1251,\n",
       "  1252,\n",
       "  1253,\n",
       "  1254,\n",
       "  1255,\n",
       "  1256,\n",
       "  1257,\n",
       "  1258,\n",
       "  1259,\n",
       "  1260,\n",
       "  1261,\n",
       "  1262,\n",
       "  1263,\n",
       "  1264,\n",
       "  1265,\n",
       "  1266,\n",
       "  1267,\n",
       "  1268,\n",
       "  1269,\n",
       "  1270,\n",
       "  1271,\n",
       "  1272,\n",
       "  1273,\n",
       "  1274,\n",
       "  1275,\n",
       "  1276,\n",
       "  1277,\n",
       "  1278,\n",
       "  1279,\n",
       "  1280,\n",
       "  1281,\n",
       "  1282,\n",
       "  1283,\n",
       "  1284,\n",
       "  1285,\n",
       "  1286,\n",
       "  1287,\n",
       "  1288,\n",
       "  1289,\n",
       "  1290,\n",
       "  1291,\n",
       "  1292,\n",
       "  1293,\n",
       "  1294,\n",
       "  1295,\n",
       "  1296,\n",
       "  1297,\n",
       "  1298,\n",
       "  1299,\n",
       "  1300,\n",
       "  1301,\n",
       "  1302,\n",
       "  1303,\n",
       "  1304,\n",
       "  1305,\n",
       "  1306,\n",
       "  1307,\n",
       "  1308,\n",
       "  1309],\n",
       " 'Survived': array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revert predictions to NumPy array\n",
    "y_pred_np = y_pred_test.int().detach().numpy()\n",
    "\n",
    "# Create a list with the correct indicies\n",
    "min_i = max(train['PassengerId'])\n",
    "y_indicies = [min_i+i+1 for i in range(len(y_pred_test))]\n",
    "\n",
    "# Make a combined list of indicies and predictions\n",
    "y_data = {'PassengerId': y_indicies, 'Survived': y_pred_np}\n",
    "\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_df = pd.DataFrame(data=y_data)\n",
    "y_pred_df.to_csv(\"basicnn_submission\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
