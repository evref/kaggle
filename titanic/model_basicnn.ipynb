{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from files\n",
    "test_X = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Split data into X:parameters and y:output\n",
    "train_y = train[\"Survived\"]\n",
    "train_X = train.drop(columns=\"Survived\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning data\n",
    "\n",
    "def clean_data(data: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    to_drop = [\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]\n",
    "    data.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    # Rephrase male and female into discrete values between 0 and 1\n",
    "    data = data.replace(\"male\", 0)\n",
    "    data = data.replace(\"female\", 1)\n",
    "\n",
    "    # Calculate avg age to replace null values with\n",
    "    avg_age = round(sum(data[\"Age\"].dropna()) / len(data[\"Age\"].dropna()))\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(avg_age)\n",
    "\n",
    "    # Calculate max values for normalization of columns\n",
    "    max_age = max(data[\"Age\"])\n",
    "    max_pclass = max(data[\"Pclass\"])\n",
    "\n",
    "    # Normalize values\n",
    "    data[\"Pclass\"] /= max_pclass\n",
    "    data[\"Age\"] /= max_age\n",
    "\n",
    "    return data\n",
    "\n",
    "# Clean both train and test data\n",
    "ctrain = clean_data(train_X)\n",
    "ctest = clean_data(test_X)\n",
    "\n",
    "# Get labels\n",
    "train_labels = ctrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set seed for torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Put data onto tensors\n",
    "train_X_tensor = torch.tensor(ctrain.to_numpy())\n",
    "train_y_tensor = torch.tensor(train_y.to_numpy())\n",
    "test_X_tensor = torch.tensor(ctest.to_numpy())\n",
    "\n",
    "# Split data into training- and validation sets\n",
    "train_split = int(0.8 * len(train_X_tensor))\n",
    "X_train, y_train = train_X_tensor[:train_split], train_y_tensor[:train_split]\n",
    "X_valid, y_valid = train_X_tensor[train_split:], train_y_tensor[train_split:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer_1): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (layer_3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load neural network\n",
    "from torch import nn\n",
    "\n",
    "# Select device (aka cpu/gpu)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(f\"Using {device} device\")\n",
    "\n",
    "# Defining the neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=3, out_features=32)\n",
    "        self.layer_2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.layer_3 = nn.Linear(in_features=32, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        layer1 = self.layer_1(x)\n",
    "        layer2 = self.layer_2(layer1)\n",
    "        layer3 = self.layer_3(layer2)\n",
    "        return layer3\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.7491713762283325, Accuracy: 39.04494382022472\n",
      "Epoch 10: Loss: 0.5588670372962952, Accuracy: 75.84269662921348\n",
      "Epoch 20: Loss: 0.47447526454925537, Accuracy: 78.37078651685393\n",
      "Epoch 30: Loss: 0.4704074263572693, Accuracy: 78.37078651685393\n",
      "Epoch 40: Loss: 0.4677979052066803, Accuracy: 78.37078651685393\n",
      "Epoch 50: Loss: 0.46601659059524536, Accuracy: 78.37078651685393\n",
      "Epoch 60: Loss: 0.4648061990737915, Accuracy: 78.51123595505618\n",
      "Epoch 70: Loss: 0.46401742100715637, Accuracy: 78.51123595505618\n",
      "Epoch 80: Loss: 0.46357131004333496, Accuracy: 78.37078651685393\n",
      "Epoch 90: Loss: 0.5146408677101135, Accuracy: 77.24719101123596\n"
     ]
    }
   ],
   "source": [
    "# Set loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optim = torch.optim.SGD(params=model.parameters(), lr=1)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_true)) * 100\n",
    "    return acc\n",
    "\n",
    "# Amount of training epochs to run\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train.float()).flatten()\n",
    "    loss = loss_fn(y_pred, y_train.float())\n",
    "\n",
    "    # Backward pass\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "    acc = accuracy_fn(y_train, y_pred)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training: Loss: 0.46467265486717224, Accuracy: 78.51123595505618\n",
      "Validation: Loss: 0.42052748799324036, Accuracy: 80.44692737430168\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_valid_pred = model(X_valid.float()).flatten()\n",
    "\n",
    "print(f\"Final training: Loss: {loss.item()}, Accuracy: {acc}\")\n",
    "\n",
    "\n",
    "loss = loss_fn(y_valid_pred, y_valid.float())\n",
    "y_valid_pred = torch.round(torch.sigmoid(y_valid_pred))\n",
    "acc = accuracy_fn(y_valid, y_valid_pred)\n",
    "print(f\"Validation: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred_test = model(test_X_tensor.float()).flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = y_pred_test.int().detach().numpy()\n",
    "y_pred_df = pd.DataFrame(y_pred_np)\n",
    "y_pred_df.to_csv(\"basicnn_submission\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
