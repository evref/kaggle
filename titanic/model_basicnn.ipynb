{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from files\n",
    "test_X = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Split data into X:parameters and y:output\n",
    "train_y = train[\"Survived\"]\n",
    "train_X = train.drop(columns=\"Survived\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning data\n",
    "\n",
    "def clean_data(data: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    to_drop = [\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]\n",
    "    data.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    # Rephrase male and female into discrete values between 0 and 1\n",
    "    data = data.replace(\"male\", 0)\n",
    "    data = data.replace(\"female\", 1)\n",
    "\n",
    "    # Calculate avg age to replace null values with\n",
    "    avg_age = round(sum(data[\"Age\"].dropna()) / len(data[\"Age\"].dropna()))\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(avg_age)\n",
    "\n",
    "    # Calculate max values for normalization of columns\n",
    "    max_age = max(data[\"Age\"])\n",
    "    max_pclass = max(data[\"Pclass\"])\n",
    "\n",
    "    # Normalize values\n",
    "    data[\"Pclass\"] /= max_pclass\n",
    "    data[\"Age\"] /= max_age\n",
    "\n",
    "    return data\n",
    "\n",
    "# Clean both train and test data\n",
    "ctrain = clean_data(train_X)\n",
    "ctest = clean_data(test_X)\n",
    "\n",
    "# Get labels\n",
    "train_labels = ctrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set seed for torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Put data onto tensors\n",
    "train_X_tensor = torch.tensor(ctrain.to_numpy())\n",
    "train_y_tensor = torch.tensor(train_y.to_numpy())\n",
    "test_X_tensor = torch.tensor(ctest.to_numpy())\n",
    "\n",
    "# Split data into training- and validation sets\n",
    "train_split = int(0.8 * len(train_X_tensor))\n",
    "X_train, y_train = train_X_tensor[:train_split], train_y_tensor[:train_split]\n",
    "X_valid, y_valid = train_X_tensor[train_split:], train_y_tensor[train_split:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer_1): Linear(in_features=3, out_features=16, bias=True)\n",
      "  (layer_2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (layer_3): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load neural network\n",
    "from torch import nn\n",
    "\n",
    "# Select device (aka cpu/gpu)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(f\"Using {device} device\")\n",
    "\n",
    "# Defining the neural network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=3, out_features=16)\n",
    "        self.layer_2 = nn.Linear(in_features=16, out_features=16)\n",
    "        self.layer_3 = nn.Linear(in_features=16, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        #x = torch.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        #x = torch.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.7835756540298462, Accuracy: 39.04494382022472\n",
      "Epoch 10: Loss: 0.6971967220306396, Accuracy: 60.95505617977528\n",
      "Epoch 20: Loss: 0.687463641166687, Accuracy: 60.95505617977528\n",
      "Epoch 30: Loss: 0.6756638288497925, Accuracy: 60.95505617977528\n",
      "Epoch 40: Loss: 0.656712532043457, Accuracy: 77.9494382022472\n",
      "Epoch 50: Loss: 0.6472126245498657, Accuracy: 78.23033707865169\n",
      "Epoch 60: Loss: 0.6432842016220093, Accuracy: 78.65168539325843\n",
      "Epoch 70: Loss: 0.6410934925079346, Accuracy: 78.51123595505618\n",
      "Epoch 80: Loss: 0.6395926475524902, Accuracy: 77.9494382022472\n",
      "Epoch 90: Loss: 0.6384506225585938, Accuracy: 77.9494382022472\n"
     ]
    }
   ],
   "source": [
    "# Set loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optim = torch.optim.SGD(params=model.parameters(), lr=1)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_true)) * 100\n",
    "    return acc\n",
    "\n",
    "# Amount of training epochs to run\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train.float()).flatten()\n",
    "    loss = loss_fn(y_pred, y_train.float())\n",
    "\n",
    "    # Backward pass\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y_pred = torch.round(y_pred)\n",
    "    acc = accuracy_fn(y_train, y_pred)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training: Loss: 0.6376174092292786, Accuracy: 77.9494382022472\n",
      "Validation: Loss: 0.6380630135536194, Accuracy: 81.56424581005587\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_valid_pred = model(X_valid.float()).flatten()\n",
    "\n",
    "print(f\"Final training: Loss: {loss.item()}, Accuracy: {acc}\")\n",
    "\n",
    "\n",
    "loss = loss_fn(y_valid_pred, y_valid.float())\n",
    "y_valid_pred = torch.round(y_valid_pred)\n",
    "acc = accuracy_fn(y_valid, y_valid_pred)\n",
    "print(f\"Validation: Loss: {loss.item()}, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred_test = model(test_X_tensor.float()).flatten()\n",
    "\n",
    "y_pred_test = torch.round(y_pred_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert predictions to NumPy array\n",
    "y_pred_np = y_pred_test.int().detach().numpy()\n",
    "\n",
    "# Create a list with the correct indicies\n",
    "min_i = max(train['PassengerId'])\n",
    "y_indicies = [min_i+i+1 for i in range(len(y_pred_test))]\n",
    "\n",
    "# Make a combined list of indicies and predictions\n",
    "y_data = {'PassengerId': y_indicies, 'Survived': y_pred_np}\n",
    "\n",
    "# Convert to Pandas Dataframe\n",
    "y_pred_df = pd.DataFrame(data=y_data)\n",
    "\n",
    "# Select file name\n",
    "import os.path\n",
    "\n",
    "filename = \"basicnn_submission.csv\"\n",
    "while os.path.isfile(filename):\n",
    "    filename = filename[:len(filename)-4] + \"(1).csv\"\n",
    "\n",
    "# Send to csv-file\n",
    "y_pred_df.to_csv(filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
